{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Steps to take beforehand\n",
    "1. Unzip reddit2012_2019.zip into directly\n",
    "2. Install gpt-2-simple for finetuning gpt. pip3 install gpt-2-simple\n",
    "3. Make sure to install Tensorflow 1. It doesn't work on tensorflow 2.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# concat all dataframes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-23T15:47:28.981258Z",
     "start_time": "2019-11-23T15:47:28.670409Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-23T15:49:35.919953Z",
     "start_time": "2019-11-23T15:49:35.485427Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\t\t\t\t  run3_results\t      run_no_clean_ccb\r\n",
      "2012_2016.csv\t\t\t  run3_walao\t      run_no_clean_china\r\n",
      "2017.csv\t\t\t  run_long_aiya       run_no_clean_gay\r\n",
      "2018.csv\t\t\t  run_long_bt4k       run_no_clean_knn\r\n",
      "2018_clean.csv\t\t\t  run_long_ccb\t      run_no_clean_lah\r\n",
      "2019.csv\t\t\t  run_long_china      run_no_clean_pap\r\n",
      "GPT - 2 model training.ipynb\t  run_long_copypaste  run_no_clean_pmd\r\n",
      "checkpoint\t\t\t  run_long_gay\t      run_no_clean_singlish\r\n",
      "csv_encoded.txt\t\t\t  run_long_james      run_no_clean_smlj\r\n",
      "gen\t\t\t\t  run_long_knn\t      run_no_clean_walao\r\n",
      "gpt2_gentext_20191113_133928.txt  run_long_lah\t      run_no_clean_yishun\r\n",
      "main.py\t\t\t\t  run_long_pap\t      samples\r\n",
      "models\t\t\t\t  run_long_pmd\t      schedule.sh\r\n",
      "reddit2012_2019.zip\t\t  run_long_singapore  schedule2.sh\r\n",
      "run3_ccb\t\t\t  run_long_singlish   schedule_long.sh\r\n",
      "run3_knn\t\t\t  run_long_smlj       text_encoded.npz\r\n",
      "run3_ns\t\t\t\t  run_long_walao      train_df.csv\r\n",
      "run3_nus\t\t\t  run_long_yishun     try2.csv\r\n",
      "run3_pap\t\t\t  run_no_clean\t      try3.csv\r\n",
      "run3_r\t\t\t\t  run_no_clean_aiya\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-23T15:47:32.573989Z",
     "start_time": "2019-11-23T15:47:29.428898Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ldap_home/james.chua/miniconda3/envs/tf2/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3049: DtypeWarning: Columns (0,1,2,3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"2012_2016.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-23T15:47:38.473074Z",
     "start_time": "2019-11-23T15:47:32.575235Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ldap_home/james.chua/miniconda3/envs/tf2/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3049: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df2=pd.read_csv(\"2017.csv\")\n",
    "df3=pd.read_csv(\"2018.csv\")\n",
    "df4=pd.read_csv(\"2019.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-23T15:47:39.489857Z",
     "start_time": "2019-11-23T15:47:38.474761Z"
    }
   },
   "outputs": [],
   "source": [
    "all_df = pd.concat([df,df2,df3,df4]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-23T15:47:46.349561Z",
     "start_time": "2019-11-23T15:47:46.346702Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Don't pretend that's not a thing you do in Singapore... I've seen 2 photographic examples already.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df.body[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-23T15:47:46.669444Z",
     "start_time": "2019-11-23T15:47:46.666972Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3515857"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-23T15:47:47.903817Z",
     "start_time": "2019-11-23T15:47:46.830243Z"
    }
   },
   "outputs": [],
   "source": [
    "#remove [removed]\n",
    "all_df = all_df[all_df.body != \"[removed]\"].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-23T15:47:48.824777Z",
     "start_time": "2019-11-23T15:47:47.905349Z"
    }
   },
   "outputs": [],
   "source": [
    "all_df = all_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-23T15:47:48.828535Z",
     "start_time": "2019-11-23T15:47:48.826134Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2992653"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffle and replace some encoding errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-23T15:47:51.413605Z",
     "start_time": "2019-11-23T15:47:48.829495Z"
    }
   },
   "outputs": [],
   "source": [
    "all_df = all_df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-23T15:47:51.425382Z",
     "start_time": "2019-11-23T15:47:51.414719Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>author</th>\n",
       "      <th>body</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1426256</td>\n",
       "      <td>174318</td>\n",
       "      <td>reddumpling</td>\n",
       "      <td>Use English to converse all the time (except e...</td>\n",
       "      <td>1493474831</td>\n",
       "      <td>2017-04-29 19:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2002658</td>\n",
       "      <td>119191</td>\n",
       "      <td>Neralo</td>\n",
       "      <td>&amp;gt; These can only be done on headphones, not...</td>\n",
       "      <td>1519722453</td>\n",
       "      <td>2018-02-27 17:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1268789</td>\n",
       "      <td>16851</td>\n",
       "      <td>asilentfilm9</td>\n",
       "      <td>Wait one more day.</td>\n",
       "      <td>1484299223</td>\n",
       "      <td>2017-01-13 06:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2130345</td>\n",
       "      <td>246878</td>\n",
       "      <td>sraelgaiznaer</td>\n",
       "      <td>What’s with the 3D version? Isn’t it good enou...</td>\n",
       "      <td>1523704828</td>\n",
       "      <td>2018-04-14 19:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1234346</td>\n",
       "      <td>1234346</td>\n",
       "      <td>shqippotato</td>\n",
       "      <td>dont u know losing internet connectivity can l...</td>\n",
       "      <td>1480854504</td>\n",
       "      <td>2016-12-04 09:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2992648</td>\n",
       "      <td>3136284</td>\n",
       "      <td>393654</td>\n",
       "      <td>WalfAkaiTsuki</td>\n",
       "      <td>Yesterday my wallet dropped out of my pocket a...</td>\n",
       "      <td>1560216032</td>\n",
       "      <td>2019-06-11 06:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2992649</td>\n",
       "      <td>2835463</td>\n",
       "      <td>92833</td>\n",
       "      <td>dontknowla</td>\n",
       "      <td>Audio mixing you need to be a chio bu then con...</td>\n",
       "      <td>1549463366</td>\n",
       "      <td>2019-02-06 22:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2992650</td>\n",
       "      <td>3237747</td>\n",
       "      <td>495117</td>\n",
       "      <td>cmonplsnotnow</td>\n",
       "      <td>I’m just wondering how people love that stuff ...</td>\n",
       "      <td>1563604484</td>\n",
       "      <td>2019-07-20 14:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2992651</td>\n",
       "      <td>1506995</td>\n",
       "      <td>255057</td>\n",
       "      <td>Hurt_cow</td>\n",
       "      <td>thanks</td>\n",
       "      <td>1498098367</td>\n",
       "      <td>2017-06-22 06:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2992652</td>\n",
       "      <td>2339403</td>\n",
       "      <td>455936</td>\n",
       "      <td>pjepej_</td>\n",
       "      <td>Depends on context and what kind of message?</td>\n",
       "      <td>1531293363</td>\n",
       "      <td>2018-07-11 15:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2992653 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         level_0    index         author  \\\n",
       "0        1426256   174318    reddumpling   \n",
       "1        2002658   119191         Neralo   \n",
       "2        1268789    16851   asilentfilm9   \n",
       "3        2130345   246878  sraelgaiznaer   \n",
       "4        1234346  1234346    shqippotato   \n",
       "...          ...      ...            ...   \n",
       "2992648  3136284   393654  WalfAkaiTsuki   \n",
       "2992649  2835463    92833     dontknowla   \n",
       "2992650  3237747   495117  cmonplsnotnow   \n",
       "2992651  1506995   255057       Hurt_cow   \n",
       "2992652  2339403   455936        pjepej_   \n",
       "\n",
       "                                                      body created_utc  \\\n",
       "0        Use English to converse all the time (except e...  1493474831   \n",
       "1        &gt; These can only be done on headphones, not...  1519722453   \n",
       "2                                       Wait one more day.  1484299223   \n",
       "3        What’s with the 3D version? Isn’t it good enou...  1523704828   \n",
       "4        dont u know losing internet connectivity can l...  1480854504   \n",
       "...                                                    ...         ...   \n",
       "2992648  Yesterday my wallet dropped out of my pocket a...  1560216032   \n",
       "2992649  Audio mixing you need to be a chio bu then con...  1549463366   \n",
       "2992650  I’m just wondering how people love that stuff ...  1563604484   \n",
       "2992651                                             thanks  1498098367   \n",
       "2992652       Depends on context and what kind of message?  1531293363   \n",
       "\n",
       "                        date  \n",
       "0        2017-04-29 19:00:00  \n",
       "1        2018-02-27 17:00:00  \n",
       "2        2017-01-13 06:00:00  \n",
       "3        2018-04-14 19:00:00  \n",
       "4        2016-12-04 09:00:00  \n",
       "...                      ...  \n",
       "2992648  2019-06-11 06:00:00  \n",
       "2992649  2019-02-06 22:00:00  \n",
       "2992650  2019-07-20 14:00:00  \n",
       "2992651  2017-06-22 06:00:00  \n",
       "2992652  2018-07-11 15:00:00  \n",
       "\n",
       "[2992653 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-23T15:49:16.719661Z",
     "start_time": "2019-11-23T15:49:16.717792Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save to csv called train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-23T15:49:32.673962Z",
     "start_time": "2019-11-23T15:49:20.300584Z"
    }
   },
   "outputs": [],
   "source": [
    "all_df[(all_df.body.str.len() > 100)].to_csv(\"train_df.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the finetuning\n",
    "You can change the model_name to \"124M\" for faster training and less memory requirements but lower quality results.\n",
    "We required 50gb of RAM for the 355M model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-23T15:57:57.092886Z",
     "start_time": "2019-11-23T15:57:57.091023Z"
    }
   },
   "outputs": [],
   "source": [
    "import gpt_2_simple as gpt2\n",
    "import os\n",
    "import requests\n",
    "\n",
    "model_name = \"355M\"\n",
    "if not os.path.isdir(os.path.join(\"models\", model_name)):\n",
    "    print(f\"Downloading {model_name} model...\")\n",
    "    gpt2.download_gpt2(model_name=model_name)   # model is saved into current directory under /models/355M/\n",
    "\n",
    "sess = gpt2.start_tf_sess()\n",
    "csv_path = \"train_df.csv\"\n",
    "gpt2.encode_csv(csv_path=csv_path, out_path=\"csv_encoded.txt\")\n",
    "gpt2.encode_dataset(file_path=\"csv_encoded.txt\", out_path=\"text_encoded.npz\")\n",
    "gpt2.finetune(sess,\n",
    "            dataset=\"text_encoded.npz\",\n",
    "            model_name=model_name,\n",
    "            steps=8000,\n",
    "            run_name='run_long',\n",
    "            print_every=10,\n",
    "            sample_every=200,\n",
    "            save_every=500,\n",
    "            overwrite=True\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run inference\n",
    "gpt_2_simple provides a command line interface\n",
    "Some examples:\n",
    "\n",
    "!gpt_2_simple generate --temperature 0.8 --nsamples 80 --batch_size 8 --prefix \"In NUS, a group of students took the module BT4222, Mining Web Data for Business Insights, under Assistant Professor Qiao Dandan. The students had to create a project using Natural Language Processing tools. One of her students, James, did not know what to do for his project and so\" --truncate \"<|endoftext|>\" --nfiles 5 --folder run_long_james --run_name run_long\n",
    "\n",
    "!gpt_2_simple generate --temperature 0.8 --nsamples 80 --batch_size 8 --prefix \"SINGAPORE\" --truncate \"<|endoftext|>\" --nfiles 5 --folder run_long_singapore --run_name run_long\n",
    "\n",
    "!gpt_2_simple generate --temperature 0.8 --nsamples 80 --batch_size 8 --prefix \"PAP\" --truncate \"<|endoftext|>\" --nfiles 5 --folder run_long_pap --run_name run_long"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf2] *",
   "language": "python",
   "name": "conda-env-tf2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
